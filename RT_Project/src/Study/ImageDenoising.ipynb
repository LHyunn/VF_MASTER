{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 15:21:24.205047: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-14 15:21:24.331338: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/VirtualFlaw/Data')\n",
    "import preprocessing.pipe as pipe\n",
    "sys.path.append('/home/VirtualFlaw/Data/refactoring/src/Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(array):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noise_factor = 0.4\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 0\n"
     ]
    }
   ],
   "source": [
    "#THICKNESS_LIST = \"ALL\"\n",
    "THICKNESS_LIST = [7.92, 8.74, 9.53]\n",
    "CATEGORY_LIST = pipe.manage_category_thickness(thickness_range=THICKNESS_LIST)\n",
    "\n",
    "image_path_list = []\n",
    "for category in CATEGORY_LIST:\n",
    "    thikness =  pipe.manage_category_thickness(category=category)\n",
    "    image_list = glob(f'/home/VirtualFlaw/Data/IMAGE/Raw_jpg_1024/{thikness}/{category}/*.jpg')\n",
    "    image_list = natsorted(image_list)\n",
    "    image_path_list += image_list[3:-3] #Exclude 3 images - EndTap, IQI\n",
    "\n",
    "if len(image_path_list) > 50000:\n",
    "    image_path_list = np.random.choice(image_path_list, 50000, replace=False)\n",
    "    \n",
    "image_path_list = shuffle(image_path_list)\n",
    "for image in image_path_list:\n",
    "    image_name = image.split('/')[-1]\n",
    "    if not image_name[-5].isdigit():\n",
    "        image_path_list.remove(image)\n",
    "        \n",
    "    \n",
    "print(f\"Total images: {len(image_path_list)}\")\n",
    "    \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 1024\n",
    "IMG_HEIGHT = 1024\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "\n",
    "MAX_IMAGE =  2000\n",
    "\n",
    "today = time.strftime('%Y%m%d %H%M', time.localtime(time.time()))\n",
    "os.makedirs(f'/home/VirtualFlaw/Data/refactoring/logs/denoising/{today}', exist_ok=True)\n",
    "shutil.copy('/home/VirtualFlaw/Data/refactoring/src/ImageDenoising.ipynb', f'/home/VirtualFlaw/Data/refactoring/logs/denoising/{today}/ImageDenoising.ipynb')\n",
    "\n",
    "\n",
    "X_train = np.zeros((MAX_IMAGE, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((MAX_IMAGE, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 209.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for n, path in tqdm(enumerate(image_path_list), total=MAX_IMAGE):\n",
    "    try:\n",
    "        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        #image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        X_train[n] = image\n",
    "        Y_train[n] = image\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = noise(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape :  (2000, 1024, 1024, 1)\n",
      "Y_train.shape :  (2000, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"X_train.shape : \", X_train.shape)\n",
    "print(\"Y_train.shape : \", Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:17:22.867495: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-11 19:17:24.462504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22294 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6\n",
      "2023-03-11 19:17:24.463604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22294 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2023-03-11 19:17:24.464590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 22294 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:86:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learning_rate = 1e-5\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with mirrored_strategy.scope():\n",
    "    #sequential model\n",
    "    model = tf.keras.Sequential()\n",
    "    #normalization\n",
    "    model.add(layers.BatchNormalization(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same',))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
    "    \n",
    "    earlystopper = EarlyStopping(patience=10, verbose=1)\n",
    "    checkpointer = ModelCheckpoint(f'/home/VirtualFlaw/Data/refactoring/logs/denoising/{today}/model.h5', verbose=1, save_best_only=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1)\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=losses.MeanSquaredError(), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 24 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:17:48.731005: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-11 19:17:50.077546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-11 19:17:51.677372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-11 19:17:57.525922: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-11 19:17:57.525962: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.52GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-03-11 19:18:00.710609: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f965e529620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-11 19:18:00.710643: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-03-11 19:18:00.710654: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-03-11 19:18:00.710658: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (2): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-03-11 19:18:00.720724: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-11 19:18:00.854378: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467/467 [==============================] - ETA: 0s - loss: 8805.4277 - accuracy: 0.0000e+00\n",
      "Epoch 1: val_loss improved from inf to 8775.78516, saving model to /home/VirtualFlaw/Data/refactoring/logs/denoising/20230311 1916/model.h5\n",
      "467/467 [==============================] - 162s 300ms/step - loss: 8805.4277 - accuracy: 0.0000e+00 - val_loss: 8775.7852 - val_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:22.580548: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/467 [..............................] - ETA: 2:21 - loss: 8478.5820 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:22.883871: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/467 [..............................] - ETA: 2:20 - loss: 8273.5146 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:23.188615: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/467 [..............................] - ETA: 2:20 - loss: 8202.4014 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:23.494231: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/467 [..............................] - ETA: 2:20 - loss: 8191.7593 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:23.797572: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/467 [..............................] - ETA: 2:20 - loss: 8338.1396 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:24.103892: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/467 [..............................] - ETA: 2:20 - loss: 8339.4932 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:24.407093: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/467 [..............................] - ETA: 2:19 - loss: 8368.1816 - accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 19:20:24.709381: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.01GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467/467 [==============================] - ETA: 0s - loss: 8805.2178 - accuracy: 0.0000e+00\n",
      "Epoch 2: val_loss improved from 8775.78516 to 8775.57031, saving model to /home/VirtualFlaw/Data/refactoring/logs/denoising/20230311 1916/model.h5\n",
      "467/467 [==============================] - 159s 340ms/step - loss: 8805.2178 - accuracy: 0.0000e+00 - val_loss: 8775.5703 - val_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 3/300\n",
      "467/467 [==============================] - ETA: 0s - loss: 8804.9990 - accuracy: 0.0000e+00\n",
      "Epoch 3: val_loss improved from 8775.57031 to 8775.35352, saving model to /home/VirtualFlaw/Data/refactoring/logs/denoising/20230311 1916/model.h5\n",
      "467/467 [==============================] - 159s 341ms/step - loss: 8804.9990 - accuracy: 0.0000e+00 - val_loss: 8775.3535 - val_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 4/300\n",
      "467/467 [==============================] - ETA: 0s - loss: 8804.7783 - accuracy: 0.0000e+00\n",
      "Epoch 4: val_loss improved from 8775.35352 to 8775.13770, saving model to /home/VirtualFlaw/Data/refactoring/logs/denoising/20230311 1916/model.h5\n",
      "467/467 [==============================] - 160s 342ms/step - loss: 8804.7783 - accuracy: 0.0000e+00 - val_loss: 8775.1377 - val_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 5/300\n",
      "467/467 [==============================] - ETA: 0s - loss: 8804.5645 - accuracy: 0.0000e+00\n",
      "Epoch 5: val_loss improved from 8775.13770 to 8774.91895, saving model to /home/VirtualFlaw/Data/refactoring/logs/denoising/20230311 1916/model.h5\n",
      "467/467 [==============================] - 160s 342ms/step - loss: 8804.5645 - accuracy: 0.0000e+00 - val_loss: 8774.9189 - val_accuracy: 0.0000e+00 - lr: 1.0000e-05\n",
      "Epoch 6/300\n",
      " 52/467 [==>...........................] - ETA: 2:07 - loss: 8863.6729 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "\n",
    "result = model.fit(X_train, Y_train, validation_split=0.3, batch_size=3, epochs=300, callbacks=[earlystopper, checkpointer, reduce_lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at /home/VirtualFlaw/Data/refactoring/logs/denoising/20230311 1859/model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/home/VirtualFlaw/Data/refactoring/logs/denoising/\u001b[39;49m\u001b[39m{\u001b[39;49;00mtoday\u001b[39m}\u001b[39;49;00m\u001b[39m/model.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/VirtualFlaw/Data/Raw_jpg/202212/REJ/7.92/22I002-02-012/22I002-02-012-1st-1-(1)-38-R-UC.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_path, cv2\u001b[39m.\u001b[39mIMREAD_GRAYSCALE)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/save.py:227\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    226\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 227\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    228\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[1;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    232\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    233\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    234\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at /home/VirtualFlaw/Data/refactoring/logs/denoising/20230311 1859/model.h5"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(f\"/home/VirtualFlaw/Data/refactoring/logs/denoising/{today}/model.h5\")\n",
    "image_path = \"/home/VirtualFlaw/Data/Raw_jpg/202212/REJ/7.92/22I002-02-012/22I002-02-012-1st-1-(1)-38-R-UC.jpg\"\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "image = np.expand_dims(image, axis=-1)\n",
    "image = np.expand_dims(image, axis=0)\n",
    "image = image.astype(np.float32)\n",
    "image = image / 255.0\n",
    "\n",
    "pred = model.predict(image)\n",
    "pred = cv2.normalize(pred, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "\n",
    "cv2.imwrite(f\"/home/VirtualFlaw/Data/refactoring/logs/denoising/{today}/denoised.jpg\", pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
